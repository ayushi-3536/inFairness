{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJVavyZ/3fZ0dCNM8MAzCN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushi-3536/inFairness/blob/main/examples/compas_recidivism_prediction/compas_recidivism_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRKygf82fr6t",
        "outputId": "8ea2f14a-9e84-4a03-f828-f1c3f2da606c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting inFairness\n",
            "  Downloading inFairness-0.2.2-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.7/dist-packages (from inFairness) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.7/dist-packages (from inFairness) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.5.4 in /usr/local/lib/python3.7/dist-packages (from inFairness) (1.7.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from inFairness) (1.12.1+cu113)\n",
            "Collecting functorch~=0.1.1\n",
            "  Downloading functorch-0.1.1-cp37-cp37m-manylinux1_x86_64.whl (21.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.4 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting POT>=0.8.0\n",
            "  Downloading POT-0.8.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (664 kB)\n",
            "\u001b[K     |████████████████████████████████| 664 kB 60.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from inFairness) (1.0.2)\n",
            "Collecting torch>=1.11.0\n",
            "  Downloading torch-1.11.0-cp37-cp37m-manylinux1_x86_64.whl (750.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 750.6 MB 13 kB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.3.5->inFairness) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.3.5->inFairness) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.3.5->inFairness) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.2->inFairness) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.2->inFairness) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.11.0->inFairness) (4.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Installing collected packages: torch, POT, functorch, inFairness\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.11.0 which is incompatible.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.11.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.11.0 which is incompatible.\u001b[0m\n",
            "Successfully installed POT-0.8.2 functorch-0.1.1 inFairness-0.2.2 torch-1.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install inFairness requests\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from inFairness.fairalgo import SenSeI\n",
        "from inFairness import distances\n",
        "from inFairness.auditor import SenSRAuditor, SenSeIAuditor\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyWI9KXMgzvP",
        "outputId": "e6977f35-a9ee-4327-bba8-3b11a2437936"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ayushi-3536/inFairness.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uq9cfnr1mjwC",
        "outputId": "1ef5b165-ba0a-4662-b47d-49dae8cbe973"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'inFairness'...\n",
            "remote: Enumerating objects: 343, done.\u001b[K\n",
            "remote: Counting objects: 100% (128/128), done.\u001b[K\n",
            "remote: Compressing objects: 100% (91/91), done.\u001b[K\n",
            "remote: Total 343 (delta 75), reused 40 (delta 36), pack-reused 215\u001b[K\n",
            "Receiving objects: 100% (343/343), 1.46 MiB | 27.20 MiB/s, done.\n",
            "Resolving deltas: 100% (132/132), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd inFairness"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9aghE6mg1Dg",
        "outputId": "70f0a32f-a96b-4ed3-8863-fb16e145599c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/inFairness\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e .\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa6Gg_KHmsdw",
        "outputId": "40895bf4-e583-4359-eeee-363e11d45387"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/inFairness\n",
            "Requirement already satisfied: functorch~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from inFairness==0.2.2) (0.1.1)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.7/dist-packages (from inFairness==0.2.2) (1.21.6)\n",
            "Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.7/dist-packages (from inFairness==0.2.2) (1.3.5)\n",
            "Requirement already satisfied: POT>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from inFairness==0.2.2) (0.8.2)\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from inFairness==0.2.2) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.5.4 in /usr/local/lib/python3.7/dist-packages (from inFairness==0.2.2) (1.7.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from inFairness==0.2.2) (1.11.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.3.5->inFairness==0.2.2) (2022.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.3.5->inFairness==0.2.2) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.3.5->inFairness==0.2.2) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.2->inFairness==0.2.2) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.2->inFairness==0.2.2) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.11.0->inFairness==0.2.2) (4.1.1)\n",
            "Installing collected packages: inFairness\n",
            "  Attempting uninstall: inFairness\n",
            "    Found existing installation: inFairness 0.2.2\n",
            "    Uninstalling inFairness-0.2.2:\n",
            "      Successfully uninstalled inFairness-0.2.2\n",
            "  Running setup.py develop for inFairness\n",
            "Successfully installed inFairness-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd examples/compas_recidivism_prediction/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQJ3rkJ9tAfk",
        "outputId": "329ccd99-da44-4b79-c42e-1c5329e3e928"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/inFairness/examples/compas_recidivism_prediction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from inFairness.fairalgo import SenSeI\n",
        "from inFairness import distances\n",
        "from inFairness.auditor import SenSRAuditor, SenSeIAuditor\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6p9Gg972m3Ut",
        "outputId": "90eddea4-c02c-44f4-e2a9-d6d5656d26e9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "        return data, label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "lUKFhH1ztJoN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_input_output_df(data,target):\n",
        "\n",
        "    cols = sorted(data.columns)\n",
        "    output_col = target\n",
        "    input_cols = [col for col in cols if col not in output_col]\n",
        "\n",
        "    df_X = data[input_cols]\n",
        "    df_Y = data[output_col]\n",
        "    \n",
        "    return df_X, df_Y"
      ],
      "metadata": {
        "id": "hYa7j_rpNJNq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "compas= 'https://github.com/propublica/compas-analysis/raw/master/compas-scores-two-years.csv'\n",
        "data_df = pd.read_csv(compas,index_col=0,parse_dates=[0])\n",
        "cols_to_drop = [\n",
        "        'name','first','last','compas_screening_date','dob','age_cat',\n",
        "        'v_screening_date','in_custody','out_custody','start','end',\n",
        "        'c_jail_in', 'c_jail_out', 'c_case_number', 'c_offense_date',\n",
        "       'c_arrest_date', 'c_days_from_compas',\n",
        "       'c_charge_desc', 'is_recid', 'r_case_number', \n",
        "       'r_days_from_arrest', 'r_offense_date', 'r_charge_desc', 'r_jail_in',\n",
        "       'r_jail_out', 'violent_recid', 'is_violent_recid', 'vr_case_number',\n",
        "       'vr_charge_degree', 'vr_offense_date', 'vr_charge_desc',\n",
        "       'screening_date','days_b_screening_arrest',\n",
        "       'v_type_of_assessment', 'v_decile_score', 'v_score_text','event'\n",
        "    ]\n",
        "\n",
        "data_df.drop(cols_to_drop, axis=1, inplace=True)\n",
        "\n",
        "\n",
        "categorical_vars = [\n",
        "        'sex', 'race', 'c_charge_degree','r_charge_degree', \n",
        "        'type_of_assessment', 'score_text'\n",
        "    ]\n",
        "data_df = pd.get_dummies(data_df, columns=categorical_vars)\n",
        "cols_to_drop=['race_Asian', 'race_Caucasian', 'race_Hispanic', 'race_Native American',\n",
        "       'race_Other','sex_Female']\n",
        "\n",
        "data_df.drop(cols_to_drop, axis=1, inplace=True)\n",
        "train_data = data_df.sample(frac=0.8, random_state=123)\n",
        "test_data = data_df.drop(train_data.index).reset_index(drop=True)\n",
        "train_data = train_data.reset_index(drop=True)\n",
        "continuous_vars = [\n",
        "    'juv_fel_count', 'decile_score', 'juv_misd_count',\n",
        "    'juv_other_count', 'priors_count','decile_score.1', \n",
        "    'priors_count.1'\n",
        "    ]\n",
        "scaler = StandardScaler().fit(train_data[continuous_vars])\n",
        "train_data[continuous_vars] = scaler.transform(train_data[continuous_vars])\n",
        "test_data[continuous_vars] = scaler.transform(test_data[continuous_vars])\n",
        "\n",
        "train_data = get_input_output_df(train_data,'two_year_recid')\n",
        "test_data = get_input_output_df(test_data,'two_year_recid')\n",
        "\n",
        "X_train_df, Y_train_df = train_data\n",
        "X_test_df, Y_test_df = test_data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0FOtdIZRvtTE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_df_to_tensor(data_X_df, data_Y_df):\n",
        "\n",
        "    data_X = torch.tensor(data_X_df.values).float()\n",
        "    data_Y = torch.tensor(data_Y_df.values)\n",
        "\n",
        "    return data_X, data_Y"
      ],
      "metadata": {
        "id": "vsVchTgzN1Qb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "protected_vars = ['sex_Male', 'race_African-American']\n",
        "protected_idxs = [X_train_df.columns.get_loc(var) for var in protected_vars]\n",
        "X_train, y_train = convert_df_to_tensor(X_train_df, Y_train_df)\n",
        "X_test, y_test = convert_df_to_tensor(X_test_df, Y_test_df)\n",
        "X_train_df, Y_train_df = train_data\n",
        "X_test_df, Y_test_df = test_data\n",
        "train_ds = Dataset(X_train, y_train)\n",
        "test_ds = Dataset(X_test, y_test)\n",
        "# Create train and test dataloaders\n",
        "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "test_dl = DataLoader(test_ds, batch_size=1000, shuffle=False)\n"
      ],
      "metadata": {
        "id": "_QrdlH7hAUUM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a fully connected neural network\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, output_size):\n",
        "\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 100)\n",
        "        self.fc2 = nn.Linear(100, 100)\n",
        "        self.fcout = nn.Linear(100, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fcout(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "pNaPUChKOF4i"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import metrics\n",
        "device = torch.device('cpu')\n",
        "input_size = X_train.shape[1]\n",
        "output_size = 2\n",
        "network_standard = Model(input_size, output_size).to(device)\n",
        "optimizer = torch.optim.Adam(network_standard.parameters(), lr=1e-3)\n",
        "loss_fn = F.cross_entropy\n",
        "\n",
        "EPOCHS = 10\n",
        "network_standard.train()\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "      for x, y in train_dl:\n",
        "\n",
        "          x, y = x.to(device), y.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          y_pred = network_standard(x).squeeze()\n",
        "          loss = loss_fn(y_pred, y)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "      if epoch % 10 == 0:\n",
        "          print(f'{epoch} completed')\n",
        "accuracy = metrics.accuracy(network_standard, test_dl, device)\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aO-xzaa4ER5z",
        "outputId": "2528d7e0-fe91-4af3-8788-78599a59a164"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 completed\n",
            "Accuracy: 0.9708939790725708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Individually fair training\n",
        "network_fair = Model(input_size, output_size).to(device)\n",
        "optimizer = torch.optim.Adam(network_fair.parameters(), lr=1e-3)\n",
        "lossfn = F.cross_entropy\n",
        "\n",
        "distance_x = distances.SVDSensitiveSubspaceDistance()\n",
        "distance_y = distances.SquaredEuclideanDistance()\n",
        "\n",
        "distance_x.fit(X_train, n_components=10)\n",
        "distance_y.fit(num_dims=output_size)\n",
        "\n",
        "distance_x.to(device)\n",
        "distance_y.to(device)\n",
        "\n",
        "rho = 5.0\n",
        "eps = 0.1\n",
        "auditor_nsteps = 100\n",
        "auditor_lr = 1e-3\n",
        "\n",
        "fairalgo = SenSeI(network_fair, distance_x, distance_y, lossfn, rho, eps, auditor_nsteps, auditor_lr)\n",
        "\n",
        "fairalgo.train()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    for x, y in train_dl:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        result = fairalgo(x, y)\n",
        "        result.loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "        print(f'{epoch} completed')\n",
        "\n",
        "accuracy = metrics.accuracy(network_fair, test_dl, device)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3JzKyEFDCC-",
        "outputId": "b950b02f-b7ab-4adf-c9a3-525d443a063a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 completed\n",
            "Accuracy: 0.8967428803443909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Auditing using the SenSR Auditor\n",
        "\n",
        "audit_nsteps = 1000\n",
        "audit_lr = 0.1\n",
        "\n",
        "auditor = SenSRAuditor(loss_fn=loss_fn, distance_x=distance_x, num_steps=audit_nsteps, lr=audit_lr, max_noise=0.5, min_noise=-0.5)\n",
        "\n",
        "audit_result_stdmodel = auditor.audit(network_standard, X_test, y_test, lambda_param=10.0, audit_threshold=1.15)\n",
        "audit_result_fairmodel = auditor.audit(network_fair, X_test, y_test, lambda_param=10.0, audit_threshold=1.15)\n",
        "\n",
        "print(\"=\"*100)\n",
        "print(f\"Loss ratio (Standard model) : {audit_result_stdmodel.lower_bound}. Is model fair: {audit_result_stdmodel.is_model_fair}\")\n",
        "print(f\"Loss ratio (fair model) : {audit_result_fairmodel.lower_bound}. Is model fair: {audit_result_fairmodel.is_model_fair}\")\n",
        "print(\"-\"*100)\n",
        "print(\"\\t As signified by these numbers, the fair model is fairer than the standard model\")\n",
        "print(\"=\"*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVrCn1veD1zm",
        "outputId": "971e6de6-3840-4896-fd8b-eaf89ba290c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/inFairness/auditor/auditor.py:54: RuntimeWarning: invalid value encountered in true_divide\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "Loss ratio (Standard model) : 542.5004962436053. Is model fair: False\n",
            "Loss ratio (fair model) : 1.0210911146684414. Is model fair: True\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\t As signified by these numbers, the fair model is fairer than the standard model\n",
            "====================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Auditing using the SenSeI Auditor\n",
        "\n",
        "audit_nsteps = 500\n",
        "audit_lr = 0.001\n",
        "\n",
        "auditor = SenSeIAuditor(distance_x=distance_x, distance_y=distance_y, num_steps=audit_nsteps, lr=audit_lr, max_noise=0.5, min_noise=-0.5)\n",
        "\n",
        "audit_result_stdmodel = auditor.audit(network_standard, X_test, y_test, loss_fn, audit_threshold=1.15, lambda_param=50.0)\n",
        "audit_result_fairmodel = auditor.audit(network_fair, X_test, y_test, loss_fn, audit_threshold=1.15, lambda_param=50.0)\n",
        "\n",
        "print(\"=\"*100)\n",
        "print(f\"Loss ratio (Standard model) : {audit_result_stdmodel.lower_bound}. Is model fair: {audit_result_stdmodel.is_model_fair}\")\n",
        "print(f\"Loss ratio (fair model) : {audit_result_fairmodel.lower_bound}. Is model fair: {audit_result_fairmodel.is_model_fair}\")\n",
        "print(\"-\"*100)\n",
        "print(\"\\t As signified by these numbers, the fair model is fairer than the standard model\")\n",
        "print(\"=\"*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8K4kTeEEyLu",
        "outputId": "0cabb70c-4852-4c35-dd24-24c6b406b131"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/inFairness/auditor/auditor.py:54: RuntimeWarning: invalid value encountered in true_divide\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "Loss ratio (Standard model) : 358036.5740139965. Is model fair: False\n",
            "Loss ratio (fair model) : 1.0036988178130457. Is model fair: True\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\t As signified by these numbers, the fair model is fairer than the standard model\n",
            "====================================================================================================\n"
          ]
        }
      ]
    }
  ]
}